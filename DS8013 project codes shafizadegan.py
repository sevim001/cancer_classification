# -*- coding: utf-8 -*-
"""deep-learning (3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DInayS_x5_i8SXxJYsRx4T6BKghfcwPA

#  Multiple cancer classification and analysis üìä
"""

import tensorflow as tf
from tensorflow import keras
from keras import layers, optimizers, losses
from keras.applications import MobileNetV3Large
from keras.applications.mobilenet_v3 import preprocess_input
from keras.preprocessing import image_dataset_from_directory, image
import numpy as np
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model

"""# Loadig the dataset and deviding it into testset and validation set üíª"""

BATCH = 16
SIZE = (224,224)

directory = "/kaggle/input/multi-cancer/Multi Cancer/Multi Cancer"

def data_loading(types, subset):
    print(f"{types}'s {subset} dataset")
    directory1 = directory + "/" + types
    dataset = image_dataset_from_directory(
        directory1,
        labels = "inferred",
        label_mode = "categorical",
        validation_split = 0.2,
        subset = subset,
        shuffle = True,
        seed = 123,
        batch_size = BATCH,
        image_size = SIZE,
    )
    return dataset

brain_dataset_train = data_loading("Brain Cancer", "training")
brain_dataset_val = data_loading("Brain Cancer", "validation")
breast_dataset_train = data_loading("Breast Cancer", "training")
breast_dataset_val = data_loading("Breast Cancer", "validation")
cervical_dataset_train = data_loading("Cervical Cancer", "training")
cervical_dataset_val = data_loading("Cervical Cancer", "validation")
kidney_dataset_train = data_loading("Kidney Cancer", "training")
kidney_dataset_val = data_loading("Kidney Cancer", "validation")
colon_dataset_train = data_loading("Lung and Colon Cancer", "training")
colon_dataset_val = data_loading("Lung and Colon Cancer", "validation")
lymphoma_dataset_train = data_loading("Lymphoma", "training")
lymphoma_dataset_val = data_loading("Lymphoma", "validation")
oral_dataset_train = data_loading("Oral Cancer", "training")
oral_dataset_val = data_loading("Oral Cancer", "validation")

import tensorflow as tf
import os

def filtered_data_loading(exclude_type, subset):
    print(f"Loading multi-cancer dataset excluding {exclude_type}")
    full_dir = "/kaggle/input/multi-cancer/Multi Cancer/Multi Cancer"
    class_dirs = [
        d for d in os.listdir(full_dir)
        if os.path.isdir(os.path.join(full_dir, d)) and d != exclude_type
    ]
    temp_dir = "/kaggle/working/filtered_data"

    # Create symlinked structure
    if not os.path.exists(temp_dir):
        os.makedirs(temp_dir)
        for d in class_dirs:
            os.symlink(os.path.join(full_dir, d), os.path.join(temp_dir, d))

    return tf.keras.preprocessing.image_dataset_from_directory(
        temp_dir,
        labels="inferred",
        label_mode="categorical",
        validation_split=0.2,
        subset=subset,
        seed=123,
        shuffle=True,
        batch_size=16,
        image_size=(224, 224)
    )

main_dataset_train = filtered_data_loading("ALL", "training")
main_dataset_val = filtered_data_loading("ALL", "validation")

main_dataset_train.class_names

import matplotlib.pyplot as plt
import numpy as np
import math

# your class names
class_names = main_dataset_train.class_names

# prepare a dict to hold one example image per class
rep_images = {cls: None for cls in class_names}

# iterate until you‚Äôve seen one image of each class
for batch in main_dataset_train.unbatch().batch(1):
    img, label = batch
    idx = np.argmax(label.numpy())
    cls = class_names[idx]
    if rep_images[cls] is None:
        rep_images[cls] = img[0].numpy().astype("uint8")
    if all(v is not None for v in rep_images.values()):
        break

n = len(class_names)
cols = 4
rows = math.ceil(n / cols)

plt.figure(figsize=(cols * 3, rows * 3))
for i, cls in enumerate(class_names):
    ax = plt.subplot(rows, cols, i + 1)
    ax.imshow(rep_images[cls])
    ax.set_title(cls)
    ax.axis("off")

plt.tight_layout()
plt.show()

import os

root_path = "/kaggle/input/multi-cancer/Multi Cancer/Multi Cancer"

def list_subtypes(cancer_type):
    path = os.path.join(root_path, cancer_type)
    if os.path.exists(path):
        subtypes = sorted(os.listdir(path))
        print(f"{cancer_type} subtypes: {subtypes}")
    else:
        print(f"{cancer_type} folder not found.")

# Example usage
list_subtypes("Brain Cancer")
list_subtypes("Breast Cancer")
list_subtypes("Cervical Cancer")
list_subtypes("Lung and Colon Cancer")
list_subtypes("Lymphoma")
list_subtypes("Kidney Cancer")
list_subtypes("Oral Cancer")

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

def show_sample_images(cancer_type, n=3):
    path = os.path.join(root_path, cancer_type)
    subtypes = os.listdir(path)

    for subtype in subtypes:
        subtype_path = os.path.join(path, subtype)
        images = os.listdir(subtype_path)[:n]
        print(f"{subtype} sample images:")
        plt.figure(figsize=(10, 2))
        for i, img_name in enumerate(images):
            img_path = os.path.join(subtype_path, img_name)
            img = mpimg.imread(img_path)
            plt.subplot(1, n, i + 1)
            plt.imshow(img)
            plt.title(subtype)
            plt.axis("off")
        plt.show()

import os
root_path = "/kaggle/input/multi-cancer/Multi Cancer/Multi Cancer"  # Define if not already
show_sample_images("Brain Cancer", n=1)

import os
root_path = "/kaggle/input/multi-cancer/Multi Cancer/Multi Cancer"  # Define if not already
show_sample_images("Breast Cancer", n=1)

import os
root_path = "/kaggle/input/multi-cancer/Multi Cancer/Multi Cancer"  # Define if not already
show_sample_images("Cervical Cancer", n=1)

import os
root_path = "/kaggle/input/multi-cancer/Multi Cancer/Multi Cancer"  # Define if not already
show_sample_images("Oral Cancer", n=1)

import os
root_path = "/kaggle/input/multi-cancer/Multi Cancer/Multi Cancer"  # Define if not already
show_sample_images("Kidney Cancer", n=1)

import os
root_path = "/kaggle/input/multi-cancer/Multi Cancer/Multi Cancer"  # Define if not already
show_sample_images("Lymphoma", n=1)

import os
root_path = "/kaggle/input/multi-cancer/Multi Cancer/Multi Cancer"  # Define if not already
show_sample_images("Lung and Colon Cancer", n=1)

"""# the pre-trained MobileNetV3 model"""

from tensorflow.keras.applications import MobileNetV3Large
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam

def create_model(num_classes):
    # Load the pre-trained MobileNetV3 model
    pre_model = MobileNetV3Large(
        weights='/kaggle/input/model/keras/default/1/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5',
        include_top=False,
        input_shape=(224, 224, 3)
    )

    # Freeze the base model layers to use transfer learning
    pre_model.trainable = False

    # Add custom classification layers
    x = pre_model.output
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(1024, activation='relu')(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.Dense(128, activation='relu')(x)
    output_layer = layers.Dense(num_classes, activation='softmax')(x)

    # Create the final model
    model = models.Model(inputs=pre_model.input, outputs=output_layer)

    # Compile the model
    model.compile(
        loss='categorical_crossentropy',
        optimizer=Adam(learning_rate=0.0001),
        metrics=['accuracy']
    )

    return model

def train_model(train_data, val_data, num_classes, model_name):
    model = create_model(num_classes)
    history = model.fit(train_data, validation_data=val_data, epochs=10)  # Store history
    model.save(f"{model_name}_model.h5")
    return history, model  # Return both history and model

def train_model_oral(train_data, val_data, num_classes, model_name):
    model = create_model(num_classes)
    history = model.fit(train_data, validation_data=val_data, epochs=15)  # Store history
    model.save(f"{model_name}_model.h5")
    return history, model  # Return both history and model

"""# distribution plot"""

import matplotlib.pyplot as plt

def plot_class_distribution(dataset, title):
    class_counts = {}
    class_names = dataset.class_names  # Get class labels
    for images, labels in dataset:
        for label in labels.numpy():
            class_index = label.argmax()
            class_counts[class_names[class_index]] = class_counts.get(class_names[class_index], 0) + 1

    plt.figure(figsize=(8, 5))
    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')
    plt.xlabel("Classes")
    plt.ylabel("Count")
    plt.title(title)
    plt.xticks(rotation=45)
    plt.show()

"""# Training hsitory and accuracy plot"""

def plot_training_history(history):
    plt.figure(figsize=(12, 5))

    # Accuracy Plot
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title("Model Accuracy")

    # Loss Plot
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.title("Model Loss")

    plt.show()

"""# confusion matrix"""

import numpy as np
import tensorflow as tf
import seaborn as sns
from sklearn.metrics import confusion_matrix

def plot_confusion_matrix(model, dataset, class_names):
    y_true = []
    y_pred = []

    for images, labels in dataset:
        predictions = model.predict(images)
        y_pred.extend(np.argmax(predictions, axis=1))
        y_true.extend(np.argmax(labels.numpy(), axis=1))

    cm = confusion_matrix(y_true, y_pred)

    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.title("Confusion Matrix")
    plt.show()

"""# Sample Prediction Plotting"""

import random

def plot_sample_predictions(model, dataset, class_names):
    images, labels = next(iter(dataset))
    predictions = model.predict(images)

    num_images = images.shape[0]
    plt.figure(figsize=(10, 10))
    for i in range(min(9, num_images)):  # Show up to 9 images, but not more than available
        plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        pred_label = class_names[np.argmax(predictions[i])]
        true_label = class_names[np.argmax(labels[i].numpy())]
        plt.title(f"Pred: {pred_label}\nTrue: {true_label}", color="green" if pred_label == true_label else "red")
        plt.axis("off")
plt.show()

"""#  generate_gradcam_heatmap function"""

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import cv2

def generate_gradcam_heatmap(model, image, class_index, last_conv_layer_name="conv_1"):
    """
    Generate and display a Grad-CAM heatmap for a given image and class index.

    Args:
        model: Trained Keras model.
        image: Input image (preprocessed, shape=(1, height, width, channels)).
        class_index: Index of the target class (e.g., cancer type).
        last_conv_layer_name: Name of the last convolutional layer (default: "conv_1").
    """
    # Create a model that outputs the last conv layer and predictions
    grad_model = tf.keras.models.Model(
        [model.inputs],
        [model.get_layer(last_conv_layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(image)
        loss = predictions[:, class_index]

    # Gradient of loss w.r.t. conv layer output
    grads = tape.gradient(loss, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    conv_outputs = conv_outputs[0]
    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap + 1e-10)  # avoid div by zero
    heatmap = heatmap.numpy()

    # Resize heatmap to match input image size
    heatmap_resized = cv2.resize(heatmap, (image.shape[2], image.shape[1]))
    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)

    # Prepare original image for overlay
    img_display = image[0].numpy()
    if np.max(img_display) <= 1.0:
        img_display = np.uint8(255 * img_display)
    else:
        img_display = np.uint8(img_display)

    # If grayscale, convert to 3 channels
    if img_display.shape[-1] == 1:
        img_display = np.repeat(img_display, 3, axis=-1)

    # Convert to BGR for OpenCV overlay
    img_display_bgr = cv2.cvtColor(img_display, cv2.COLOR_RGB2BGR)

    # Overlay heatmap on image
    superimposed_img = cv2.addWeighted(img_display_bgr, 0.6, heatmap_colored, 0.4, 0)

    # Display
    plt.figure(figsize=(10, 4))

    plt.subplot(1, 3, 1)
    plt.title("Original Image")
    plt.imshow(cv2.cvtColor(img_display_bgr, cv2.COLOR_BGR2RGB))
    plt.axis("off")

    plt.subplot(1, 3, 2)
    plt.title("Grad-CAM Heatmap")
    plt.imshow(heatmap_resized, cmap='jet')
    plt.axis("off")

    plt.subplot(1, 3, 3)
    plt.title("Superimposed")
    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))
    plt.axis("off")

    plt.tight_layout()
    plt.show()

"""# Brain Cancer üß†"""

brain_dataset_train = data_loading("Brain Cancer", "training")
brain_dataset_val = data_loading("Brain Cancer", "validation")

num_classes_brain = 3
history, model = train_model(brain_dataset_train, brain_dataset_val, num_classes_brain, "brain_cancer")

# Now you can evaluate the model
loss, accuracy = model.evaluate(brain_dataset_val)
print(f"Evaluation Results - Loss: {loss}, Accuracy: {accuracy}")

model.save("/kaggle/working/brain_cancer_model.keras")

model = tf.keras.models.load_model("/kaggle/input/brain/keras/default/1/brain_cancer_model.keras")

plot_class_distribution(brain_dataset_train, "Brain Cancer Training Dataset Distribution")
plot_class_distribution(brain_dataset_val, "Brain Cancer Validation Dataset Distribution")

plot_training_history(history)

plot_confusion_matrix(model, brain_dataset_val, brain_dataset_val.class_names)

plot_sample_predictions(model, brain_dataset_val, brain_dataset_val.class_names)

"""# breast Cancer üî¨"""

breast_dataset_train = data_loading("Breast Cancer", "training")
breast_dataset_val = data_loading("Breast Cancer", "validation")

num_classes_breast = 2

history, model = train_model(breast_dataset_train, breast_dataset_val, num_classes_breast, "breast_cancer")

# Now you can evaluate the model
loss, accuracy = model.evaluate(breast_dataset_val)
print(f"Evaluation Results - Loss: {loss}, Accuracy: {accuracy}")

# Plot training history
plot_training_history(history)

model.save("/kaggle/working/breast_cancer_model.keras")

plot_sample_predictions(model, breast_dataset_val, breast_dataset_val.class_names)

"""# Cervical cancer ü¶†"""

cervical_dataset_train = data_loading("Cervical Cancer", "training")
cervical_dataset_val = data_loading("Cervical Cancer", "validation")

num_classes_cervical = 5

history, model = train_model(cervical_dataset_train,cervical_dataset_val, num_classes_cervical, "cervical_cancer")

# Now you can evaluate the model
loss, accuracy = model.evaluate(cervical_dataset_val)
print(f"Evaluation Results - Loss: {loss}, Accuracy: {accuracy}")

model.save("/kaggle/working/cervikal_cancer_model.keras")

# Plot training history
plot_training_history(history)

plot_sample_predictions(model, cervical_dataset_val, cervical_dataset_val.class_names)

kidney_dataset_train = data_loading("Kidney Cancer", "training")
kidney_dataset_val = data_loading("Kidney Cancer", "validation")

num_classes_kidney = 2

history, model = train_model(kidney_dataset_train, kidney_dataset_val, num_classes_kidney, "kidney_cancer")

# Now you can evaluate the model
loss, accuracy = model.evaluate(kidney_dataset_val)
print(f"Evaluation Results - Loss: {loss}, Accuracy: {accuracy}")

model.save("/kaggle/working/kidney_cancer_model.keras")

# Plot training history
plot_training_history(history)

plot_sample_predictions(model, kidney_dataset_val, kidney_dataset_val.class_names)

"""# Lung and Colon Cancer üß¨"""

colon_dataset_train = data_loading("Lung and Colon Cancer", "training")
colon_dataset_val = data_loading("Lung and Colon Cancer", "validation")

num_classes_colon = 5
history, model = train_model(colon_dataset_train, colon_dataset_val, num_classes_colon, "Lung and Colon_cancer")

# Now you can evaluate the model
loss, accuracy = model.evaluate(colon_dataset_val)
print(f"Evaluation Results - Loss: {loss}, Accuracy: {accuracy}")

model.save("/kaggle/working/colon_cancer_model.keras")

# Plot training history
plot_training_history(history)

plot_sample_predictions(model, colon_dataset_val, colon_dataset_val.class_names)

"""# Lymphoma üíä"""

lymphoma_dataset_train = data_loading("Lymphoma", "training")
lymphoma_dataset_val = data_loading("Lymphoma", "validation")

num_classes_lymphoma = 3
history, model = train_model(lymphoma_dataset_train, lymphoma_dataset_val, num_classes_lymphoma, "Lymphoma")

# Now you can evaluate the model
loss, accuracy = model.evaluate(lymphoma_dataset_val)
print(f"Evaluation Results - Loss: {loss}, Accuracy: {accuracy}")

model.save("/kaggle/working/lymphoma_cancer_model.keras")

# Plot training history
plot_training_history(history)

plot_sample_predictions(model, lymphoma_dataset_val, lymphoma_dataset_val.class_names)

"""# Oral cancer üß´"""

oral_dataset_train = data_loading("Oral Cancer", "training")
oral_dataset_val = data_loading("Oral Cancer", "validation")

num_classes_oral = 2
history, model = train_model_oral(oral_dataset_train, oral_dataset_val, num_classes_oral, "Oral_cancer")

# Now you can evaluate the model
loss, accuracy = model.evaluate(oral_dataset_val)
print(f"Evaluation Results - Loss: {loss}, Accuracy: {accuracy}")

# Plot training history
plot_training_history(history)



import tensorflow as tf
from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomHeight, RandomWidth

# Define image augmentation layers
data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.2),
    tf.keras.layers.RandomContrast(0.1)
])

callbacks = [
    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3),
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
]


# Modify the data_loading function to include augmentation for training data
def data_loading(types, subset):
    print(f"{types}'s {subset} dataset")
    directory1 = directory + "/" + types
    dataset = tf.keras.preprocessing.image_dataset_from_directory(
        directory1,
        labels="inferred",
        label_mode="categorical",
        validation_split=0.2,
        subset=subset,
        shuffle=True,
        seed=123,
        batch_size=8,
        image_size=SIZE,
    )

    if subset == "training":
        # Apply data augmentation only on training data
        dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y))

    return dataset

# Load datasets with augmentation for training and standard for validation
oral_dataset_train = data_loading("Oral Cancer", "training")
oral_dataset_val = data_loading("Oral Cancer", "validation")

from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping

def train_model_oral_2(train_data, val_data, num_classes, model_name):
    model = create_model(num_classes)

    callbacks = [
        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),
        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)
    ]

    history = model.fit(
        train_data,
        validation_data=val_data,
        epochs=15,
        callbacks=callbacks
    )

    model.save(f"{model_name}_model.h5")
    return history, model

num_classes_oral = 2  # Update this to match the number of classes in your Oral Cancer dataset

# Train the model
history, model = train_model_oral_2(oral_dataset_train, oral_dataset_val, num_classes_oral, "Oral_cancer")

# Evaluate the model on the validation data
loss, accuracy = model.evaluate(oral_dataset_val)
print(f"Evaluation Results - Loss: {loss}, Accuracy: {accuracy}")

model.save("/kaggle/working/oral_cancer_model.keras")

# Plot training history
plot_training_history(history)

plot_sample_predictions(model, oral_dataset_val, oral_dataset_val.class_names)

"""# Accuracy comparison between cancers"""

import matplotlib.pyplot as plt

cancer_types = ['Brain', 'Breast', 'Cervical', 'Kidney', 'Colon', 'Lymphoma', 'Oral']
accuracies = [ 0.9950, 0.9980,  0.9994, 0.9994, 0.9986, 0.9879, 0.9605]

plt.figure(figsize=(10, 6))
plt.bar(cancer_types, accuracies, color='teal')
plt.ylim(0.8, 1.05)
plt.title("Validation Accuracy per Cancer Type")
plt.ylabel("Accuracy")
plt.xlabel("Cancer Type")
plt.grid(True, linestyle='--', alpha=0.6)
plt.show()

"""# Grad-CAM: Highlighting Key Image Regions for cancer classifications"""

# Get a batch from your validation dataset
image_batch, label_batch = next(iter(lymphoma_dataset_val))
image = image_batch[0]
label = label_batch[0]

# Add batch dimension
image_input = tf.expand_dims(image, axis=0)

# Predict the class
preds = model.predict(image_input)
predicted_class = tf.argmax(preds[0])

# Run Grad-CAM for the predicted class
generate_gradcam_heatmap(model, image_input, class_index=predicted_class)

# Get a batch from your validation dataset
image_batch, label_batch = next(iter(kidney_dataset_val))
image = image_batch[0]
label = label_batch[0]

# Add batch dimension
image_input = tf.expand_dims(image, axis=0)

# Predict the class
preds = model.predict(image_input)
predicted_class = tf.argmax(preds[0])

# Run Grad-CAM for the predicted class
generate_gradcam_heatmap(model, image_input, class_index=predicted_class)

# Get a batch from your validation dataset
image_batch, label_batch = next(iter(oral_dataset_val))
image = image_batch[0]
label = label_batch[0]

# Add batch dimension
image_input = tf.expand_dims(image, axis=0)

# Predict the class
preds = model.predict(image_input)
predicted_class = tf.argmax(preds[0])

# Run Grad-CAM for the predicted class
generate_gradcam_heatmap(model, image_input, class_index=predicted_class)

# Get a batch from your validation dataset
image_batch, label_batch = next(iter(cervical_dataset_val))
image = image_batch[0]
label = label_batch[0]

# Add batch dimension
image_input = tf.expand_dims(image, axis=0)

# Predict the class
preds = model.predict(image_input)
predicted_class = tf.argmax(preds[0])

# Run Grad-CAM for the predicted class
generate_gradcam_heatmap(model, image_input, class_index=predicted_class)

# Get a batch from your validation dataset
image_batch, label_batch = next(iter(colon_dataset_val))
image = image_batch[0]
label = label_batch[0]

# Add batch dimension
image_input = tf.expand_dims(image, axis=0)

# Predict the class
preds = model.predict(image_input)
predicted_class = tf.argmax(preds[0])

# Run Grad-CAM for the predicted class
generate_gradcam_heatmap(model, image_input, class_index=predicted_class)

# Get a batch from your validation dataset
image_batch, label_batch = next(iter(brain_dataset_val))
image = image_batch[0]
label = label_batch[0]

# Add batch dimension
image_input = tf.expand_dims(image, axis=0)

# Predict the class
preds = model.predict(image_input)
predicted_class = tf.argmax(preds[0])

# Run Grad-CAM for the predicted class
generate_gradcam_heatmap(model, image_input, class_index=predicted_class)

# Get a batch from your validation dataset
image_batch, label_batch = next(iter(breast_dataset_val))
image = image_batch[0]
label = label_batch[0]

# Add batch dimension
image_input = tf.expand_dims(image, axis=0)

# Predict the class
preds = model.predict(image_input)
predicted_class = tf.argmax(preds[0])

# Run Grad-CAM for the predicted class
generate_gradcam_heatmap(model, image_input, class_index=predicted_class)

"""# main dataset (including all cancer types)"""

num_classes_main = 7  # Update this to match the number of classes in your Oral Cancer dataset

# Train the model
history, model = train_model(main_dataset_train, main_dataset_val, num_classes_main, "")

# Evaluate the model on the validation data
loss, accuracy = model.evaluate(main_dataset_val)
print(f"Evaluation Results - Loss: {loss}, Accuracy: {accuracy}")

model.save("/kaggle/working/main_cancer_model.keras")

# Plot training history
plot_training_history(history)

plot_sample_predictions(model, main_dataset_val, main_dataset_val.class_names)

"""# üî¨ 1. Model Generalization Test
* # Can a model trained on brain cancer data can classify others like oral or kidney ?
"""

model = tf.keras.models.load_model("/kaggle/input/brain/keras/default/1/brain_cancer_model.keras")

import numpy as np

y_true = []
y_pred = []

for images, labels in kidney_dataset_val:
    preds = model.predict(images)
    y_pred.extend(np.argmax(preds, axis=1))
    y_true.extend(np.argmax(labels.numpy(), axis=1))

y_true = np.array(y_true)
y_pred = np.array(y_pred)

# Compute accuracy
accuracy = np.mean(y_true == y_pred)
print(f"Brain model on Kidney data ‚Äî Accuracy: {accuracy:.4f}")

model = tf.keras.models.load_model("/kaggle/input/cervical/keras/default/1/cervikal_cancer_model.keras")

import numpy as np

y_true = []
y_pred = []

for images, labels in colon_dataset_val:
    preds = model.predict(images)
    y_pred.extend(np.argmax(preds, axis=1))
    y_true.extend(np.argmax(labels.numpy(), axis=1))

y_true = np.array(y_true)
y_pred = np.array(y_pred)

# Compute accuracy
accuracy = np.mean(y_true == y_pred)
print(f"colon model on cervical data ‚Äî Accuracy: {accuracy:.4f}")

model = tf.keras.models.load_model("/kaggle/input/breast/keras/default/1/breast_cancer_model.keras")

import numpy as np

y_true = []
y_pred = []

for images, labels in kidney_dataset_val:
    preds = model.predict(images)
    y_pred.extend(np.argmax(preds, axis=1))
    y_true.extend(np.argmax(labels.numpy(), axis=1))

y_true = np.array(y_true)
y_pred = np.array(y_pred)

# Compute accuracy
accuracy = np.mean(y_true == y_pred)
print(f"breast model on Kidney data ‚Äî Accuracy: {accuracy:.4f}")

model = tf.keras.models.load_model("/kaggle/input/oral/keras/default/1/oral_cancer_model.keras")

import numpy as np

y_true = []
y_pred = []

for images, labels in lymphoma_dataset_val:
    preds = model.predict(images)
    y_pred.extend(np.argmax(preds, axis=1))
    y_true.extend(np.argmax(labels.numpy(), axis=1))

y_true = np.array(y_true)
y_pred = np.array(y_pred)

# Compute accuracy
accuracy = np.mean(y_true == y_pred)
print(f"oral model on lymphoma data ‚Äî Accuracy: {accuracy:.4f}")

"""# Showing misclassifications in main model"""

model = tf.keras.models.load_model("/kaggle/input/main_model/keras/default/1/main_cancer_model (1).keras")

import tensorflow as tf
import matplotlib.pyplot as plt

def visualize_misclassified_samples(model, dataset, class_names, max_samples=5):
    misclassified_images = []
    misclassified_preds = []
    misclassified_labels = []

    # Collect misclassified samples
    for images, labels in dataset:
        preds = model.predict(images)
        pred_classes = tf.argmax(preds, axis=1)
        true_classes = tf.argmax(labels, axis=1)

        for i in range(len(images)):
            if pred_classes[i] != true_classes[i]:
                misclassified_images.append(images[i].numpy())
                misclassified_preds.append(pred_classes[i].numpy())
                misclassified_labels.append(true_classes[i].numpy())

            if len(misclassified_images) >= max_samples:
                break
        if len(misclassified_images) >= max_samples:
            break

    # Display using Grad-CAM
    for i in range(len(misclassified_images)):
        img = tf.expand_dims(misclassified_images[i], axis=0)
        pred_idx = misclassified_preds[i]
        true_idx = misclassified_labels[i]
        print(f"‚ùå Misclassified Sample {i+1} ‚Äî True: {class_names[true_idx]}, Predicted: {class_names[pred_idx]}")
        generate_gradcam_heatmap(model, img, class_index=pred_idx)

visualize_misclassified_samples(model, main_dataset_val, main_dataset_val.class_names, max_samples=5)